{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzTN6T-SzhzP",
        "outputId": "51a0b783-2c9a-4378-ecb6-76fad12cfd5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "%pip install fastapi uvicorn python-multipart pillow tensorflow pyngrok numpy torch "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01muvicorn\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01masyncio\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
        "from fastapi.responses import JSONResponse\n",
        "from PIL import Image\n",
        "import io\n",
        "import uvicorn\n",
        "import asyncio\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qvktZZEiAtK",
        "outputId": "1323c6a3-887a-449b-b7f0-847a01279f5f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6vtbVUK63VL",
        "outputId": "51db2959-422c-4f6a-f0c2-51b12b63e98e"
      },
      "outputs": [],
      "source": [
        "# Path to the saved model\n",
        "MODEL_PATH = \"/content/drive/MyDrive/FYP-2/Model_prep/Model/truth_lens_xception_2.h5\"\n",
        "print(\"Model exists:\", os.path.exists(MODEL_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP-4rRBK7HNT",
        "outputId": "7b950b6a-d736-4a62-9f34-b0e67a2bc886"
      },
      "outputs": [],
      "source": [
        "loaded_model = load_model(MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-z8ZuoxY7LAN"
      },
      "outputs": [],
      "source": [
        "# Initialize FastAPI application\n",
        "app = FastAPI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJkq5giJwlvr",
        "outputId": "4051fc72-033c-45b6-8dc6-7b55107311ba"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    model = load_model(MODEL_PATH)\n",
        "    model.trainable = False\n",
        "    print(\"Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsQcujjw8jNE"
      },
      "outputs": [],
      "source": [
        "# Preprocessing function\n",
        "def preprocess_image(image):\n",
        "    \"\"\"\n",
        "    Preprocesses the uploaded image for the Xception model.\n",
        "    - Converts image to RGB.\n",
        "    - Resizes and normalizes the image.\n",
        "    \"\"\"\n",
        "    image = image.convert(\"RGB\")  # Ensure RGB format\n",
        "    image = image.resize((224, 224))  # Resize to model's required size\n",
        "    image = np.array(image)  # Convert to numpy array\n",
        "    image = image / 255.0  # Normalize pixel values\n",
        "    image = np.expand_dims(image, axis=0)  # Add batch dimension (1, 224, 224, 3)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebXm9UX99mI_"
      },
      "outputs": [],
      "source": [
        "@app.post(\"/predict\")\n",
        "async def predict(file: UploadFile = File(...)):\n",
        "    try:\n",
        "        # Validate file type\n",
        "        if file.content_type not in [\"image/jpeg\", \"image/png\"]:\n",
        "            raise HTTPException(status_code=400, detail=\"Unsupported file type. Please upload a JPG or PNG image.\")\n",
        "\n",
        "        # Read and process image\n",
        "        image_bytes = await file.read()\n",
        "        image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
        "\n",
        "        # Preprocess image\n",
        "        processed_image = preprocess_image(image)\n",
        "\n",
        "        # Make prediction\n",
        "        predictions = model.predict(processed_image)\n",
        "        confidence = float(predictions.max()) * 100\n",
        "        predicted_class = int(predictions.argmax())\n",
        "\n",
        "        # Adjust classification logic based on confidence\n",
        "        prediction_label = \"Real\" if confidence >= 90 else \"Fake\"\n",
        "\n",
        "        return JSONResponse(content={\n",
        "            \"prediction\": prediction_label,\n",
        "            \"confidence\": f\"{confidence:.2f}%\"\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"Error processing image: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2aIf5CNYFNb"
      },
      "outputs": [],
      "source": [
        "# Health check endpoint\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    \"\"\"\n",
        "    Health check endpoint to verify the server is running.\n",
        "    \"\"\"\n",
        "    return {\"message\": \"Truth Lens backend is running!\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcE2HhODYMmx"
      },
      "outputs": [],
      "source": [
        "# To run FastAPI in Colab\n",
        "def run_app():\n",
        "    \"\"\"\n",
        "    Runs the FastAPI server using Uvicorn.\n",
        "    \"\"\"\n",
        "    config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000)\n",
        "    server = uvicorn.Server(config)\n",
        "\n",
        "    loop = asyncio.get_event_loop() # Get the current running event loop.\n",
        "    loop.run_until_complete(server.serve()) # This code runs an asynchronous task, so you call it through loop.run_until_complete\n",
        "\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4INtGHAjtTJ1",
        "outputId": "1c266753-982e-4007-e807-86d5610f7bc5"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Set the Ngrok authentication token\n",
        "ngrok.set_auth_token(\"2s4wxdhWi2WjFU2kylwee8qHqbH_7XSvxiPspoJQshE3tFA17\")\n",
        "\n",
        "# Expose the local server to the internet\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"Public URL:\", public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UP8EFrqqtxKZ",
        "outputId": "5adf79e3-3c9a-4bcb-dffe-b1c60391b663"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "import uvicorn\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"message\": \"Hello, FastAPI with Ngrok on Colab!\"}\n",
        "\n",
        "# Patch the event loop\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Set the Ngrok authentication token\n",
        "ngrok.set_auth_token(\"2s4wxdhWi2WjFU2kylwee8qHqbH_7XSvxiPspoJQshE3tFA17\")  # Replace with your Ngrok auth token\n",
        "\n",
        "# Expose the local server to the internet\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"Public URL:\", public_url)\n",
        "\n",
        "# Run the FastAPI app\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVkwKG8aun-G"
      },
      "source": [
        "#*---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
